# face_emotion_detection_cnn
Here is a **fresh, modern, and more visually appealing** version of your README file for the Face Emotion Detection project. It focuses on **clarity**, **design structure**, and **developer appeal**, with polished language, improved formatting, and icons for engagement.

---

# ğŸ˜Š Facial Emotion Detection using Deep Learning

### ğŸ” Recognizing Emotions from Facial Expressions with Custom CNN & Real-time Web Deployment

---

## ğŸ“Œ Overview

This project demonstrates a custom-built Convolutional Neural Network (CNN) that detects and classifies human emotions from facial images into **seven categories**:

> **ğŸ˜  Angry | ğŸ˜– Disgust | ğŸ˜¨ Fear | ğŸ˜€ Happy | ğŸ˜¢ Sad | ğŸ˜² Surprise | ğŸ˜ Neutral**

Trained on grayscale facial images, the model achieves:

* âœ… **\~70% Validation Accuracy**
* âœ… **\~67% Training Accuracy**

The final model is deployed via a **Flask-based web application** for easy and interactive use.

---

## ğŸ§  Core Features

* ğŸ§± Custom CNN architecture built from scratch
* ğŸ–¼ï¸ Input: 48x48 grayscale facial images
* ğŸ”„ Real-time prediction via image upload
* ğŸ§ª Model tested and validated using best practices
* ğŸ’» User-friendly web interface built with Flask and HTML/CSS

---

## ğŸš€ Live Prediction Flow

1. User uploads a face image.
2. Image is resized & preprocessed (48x48, grayscale).
3. Image passed to trained CNN model.
4. Model returns most probable emotion.
5. Web app displays image and prediction result.

---

## ğŸ§± Project Structure

```
Emotion-Detection/
â”‚
â”œâ”€â”€ main.py                      #  Streamlit backend (Web App)
â”œâ”€â”€ Emotion_model.h5           # Trained CNN model            
â”œâ”€â”€ static/
â”‚   â””â”€â”€ face image.jpg     # Temporary uploaded image
â”œâ”€â”€ Emotion_Detection.ipynb  # Notebook for model training
â”œâ”€â”€ README.md                  # Project documentation
```

---

## ğŸ—ï¸ CNN Model Architecture

* **Layers**: Conv2D â†’ MaxPooling2D â†’ BatchNorm â†’ Dropout â†’ Dense
* **Optimizer**: Adam
* **Loss Function**: Categorical Crossentropy
* **Final Layer**: Softmax for 7-class emotion output
* **Regularization**: Dropout + Data Augmentation

ğŸ“‰ *Refer to the notebook for training metrics and architecture details.*

---

## ğŸ“Š Model Performance

| Metric           | Value                   |
| ---------------- | ----------------------- |
| Accuracy         | \~65% (val)             |
| Loss             | â†“ Converged             |
| Confusion Matrix | âœ”ï¸ Included in notebook |
| Augmentation     | âœ”ï¸ Flip, Zoom, Rotation |

---

## ğŸ§ª Technologies Used

| Category             | Tools / Libraries          |
| -------------------- | -------------------------- |
| ğŸ’» Programming       | Python                     |
| ğŸ§  Deep Learning     | TensorFlow, Keras          |
| ğŸ–¼ï¸ Image Processing | OpenCV, Pillow             |
| ğŸŒ Web Framework     | Streamlit|
| ğŸ“Š Data/Plotting     | NumPy, Matplotlib, Seaborn |

---

## ğŸ’¡ Real-World Use Cases

* ğŸ­ Emotion-aware Human-Computer Interfaces
* ğŸ§  Mental Health Monitoring & Therapy Apps
* ğŸ“Š Social Media Sentiment Analysis
* ğŸ“ Emotion-driven Customer Support Systems
* ğŸš— Driver Alertness Detection Systems

---

## ğŸ“· Sample Emotions Detected

| Emotion  | Emoji |
| -------- | ----- |
| Angry    | ğŸ˜     |
| Disgust  | ğŸ˜–    |
| Fear     | ğŸ˜¨    |
| Happy    | ğŸ˜€    |
| Sad      | ğŸ˜¢    |
| Surprise | ğŸ˜²    |
| Neutral  | ğŸ˜    |

---

## ğŸ› ï¸ How to Run Locally

1. âœ… Clone this repo:

   ```bash
   git clone https://github.com/your-username/Emotion-Detection.git
   cd Emotion-Detection
   ```

2. ğŸ”§ Install dependencies:

   ```bash
   pip install streamlit tensorflow numpy opencv-python pillow
   ```

3. ğŸš€ Launch the web app:

   ```bash
   python main.py
   ```

**Emotion Detection

https://github.com/user-attachments/assets/c205c3b6-3ba2-4572-9915-51caec6c5dfa


